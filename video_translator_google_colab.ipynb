{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "video translator google colab",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiARYNUBKOVV"
      },
      "source": [
        "# @title ##**Install modules** { display-mode: \"form\" }\n",
        "from IPython.display import clear_output\n",
        "!pip install youtube_dl\n",
        "!pip install get-video-properties\n",
        "!pip install kora\n",
        "!pip install spleeter\n",
        "!pip install gTTS==2.2.2\n",
        "!pip install pydub\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt0V0sVvIV_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40e2d7f-b9b9-4da7-f200-941946013681"
      },
      "source": [
        "# @title ##**Select storage type** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab.output import eval_js\n",
        "import os\n",
        "import glob\n",
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from subprocess import Popen, PIPE\n",
        "import re\n",
        "from videoprops import get_video_properties\n",
        "import datetime\n",
        "import shutil\n",
        "from pydub import AudioSegment\n",
        "from gtts import gTTS\n",
        "import IPython.display as ipd\n",
        "from pydub import AudioSegment\n",
        "from IPython.display import HTML\n",
        "\n",
        "#calculate video time\n",
        "def calculate_video_duration(video_file):\n",
        "  res = Popen(['ffmpeg', '-i', video_file, '-hide_banner'],stdout=PIPE,stderr=PIPE)\n",
        "  none,meta = res.communicate()\n",
        "  meta_out = meta.decode()\n",
        "  #---| Take out info\n",
        "  duration = re.search(r'Duration:.*', meta_out)\n",
        "  my_time=duration.group().split(\",\")[0].split(\"Duration:\")[-1]\n",
        "  hour,minutes,seconds=my_time.split(\":\")\n",
        "  video_in_seconds=float(hour)*60*60+float(minutes)*60+float(seconds)\n",
        "  return video_in_seconds\n",
        "def successful():\n",
        "  eval_js('new Audio(\"https://www.myinstants.com/media/sounds/anime-wow-sound-effect.mp3\").play()')    \n",
        "\n",
        "storage=\"temporary\"#@param[\"temporary\",\"google drive\"]\n",
        "parent_directory=\"\"\n",
        "if storage==\"google drive\":\n",
        "  drive.mount('/content/gdrive')\n",
        "  parent_directory=\"/content/gdrive/MyDrive\"\n",
        "  clear_output()\n",
        "  print(\"Using drive as a storage\")\n",
        "elif storage==\"temporary\":\n",
        "  os.chdir(\"/content/\")\n",
        "  parent_directory=os.getcwd()\n",
        "  print(\"Using colab as a temporary storage\")  \n",
        "\n",
        "try:\n",
        "  os.mkdir(\"input_video\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  os.mkdir(\"output_video\")    \n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using colab as a temporary storage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7nKfj6gtKGr7",
        "outputId": "a472c0f1-c763-410d-e387-36505ebc00e8"
      },
      "source": [
        "# @title ##**Choose youTube video quality** { display-mode: \"form\" }\n",
        "\n",
        "test_youtube_link = \"https://youtu.be/udeQhZHx-00\" #@param {type:\"string\"}\n",
        "youtube_quality_id=test_youtube_link.split(\"/\")\n",
        "check_all_quality=f\"!youtube-dl --list-formats https://www.youtube.com/watch?v={youtube_quality_id[-1]} | grep mp4\"\n",
        "check_all_quality"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!youtube-dl --list-formats https://www.youtube.com/watch?v=udeQhZHx-00 | grep mp4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kuuc3VlKIWe"
      },
      "source": [
        "#Copy the upper cell output and run in next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a02rZpmyKUYs",
        "outputId": "f90835df-649e-4f94-bde6-3b33b8ee8a77"
      },
      "source": [
        "!youtube-dl --list-formats https://www.youtube.com/watch?v=udeQhZHx-00 | grep mp4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140          m4a        audio only tiny  129k , m4a_dash container, mp4a.40.2@129k (44100Hz), 10.40MiB\n",
            "160          mp4        256x144    144p   35k , mp4_dash container, avc1.4d400c@  35k, 30fps, video only, 2.87MiB\n",
            "133          mp4        426x240    240p   75k , mp4_dash container, avc1.4d4015@  75k, 30fps, video only, 6.07MiB\n",
            "134          mp4        640x360    360p  138k , mp4_dash container, avc1.4d401e@ 138k, 30fps, video only, 11.11MiB\n",
            "135          mp4        854x480    480p  234k , mp4_dash container, avc1.4d401f@ 234k, 30fps, video only, 18.81MiB\n",
            "136          mp4        1280x720   720p  409k , mp4_dash container, avc1.64001f@ 409k, 30fps, video only, 32.86MiB\n",
            "298          mp4        1280x720   720p60  565k , mp4_dash container, avc1.640020@ 565k, 60fps, video only, 45.42MiB\n",
            "299          mp4        1920x1080  1080p60 1013k , mp4_dash container, avc1.64002a@1013k, 60fps, video only, 81.40MiB\n",
            "18           mp4        640x360    360p  236k , avc1.42001E, 30fps, mp4a.40.2 (44100Hz), 18.97MiB\n",
            "22           mp4        1280x720   720p  606k , avc1.64001F, 30fps, mp4a.40.2 (44100Hz) (best)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "fLGTrfm_JyJ0",
        "outputId": "9ca8397e-f3c1-46e7-ef9e-98351b4f1c60"
      },
      "source": [
        "# @title ##**Download youtube video** { display-mode: \"form\" }\n",
        "\n",
        "os.chdir(f\"{parent_directory}/input_video\")\n",
        "os.system(\"rm -rf *\")\n",
        "enter_youtube_link = \"https://youtu.be/udeQhZHx-00\" #@param {type:\"string\"}\n",
        "youtube_quality = \"Auto\"#@param [\"Manual\",\"Auto\"]\n",
        "quality_number = \"299\" #@param {type:\"string\"}\n",
        "youtube_id=enter_youtube_link.split(\"/\")\n",
        "if youtube_quality==\"Auto\":\n",
        "  dummy=\"youtube-dl --format mp4 https://www.youtube.com/watch?v=\"+youtube_id[-1]\n",
        "  if os.system(dummy) ==0:\n",
        "    print(\"Download successful\")\n",
        "  else:\n",
        "    print(\"Can't download\")\n",
        "elif youtube_quality==\"Manual\":\n",
        "  dummy=f\"youtube-dl  https://youtu.be/{youtube_id[-1]} -f {quality_number}+bestaudio\"\n",
        "  if os.system(dummy) == 0:\n",
        "    print(\"Download successful\")\n",
        "  else:\n",
        "    print(\"Can't download\")\n",
        "\n",
        "file_types=[\"mp4\",\"mkv\",\"webm\",\"mp4a\",\"avi\",\"mov\"]\n",
        "video_files=[]\n",
        "for i in file_types:\n",
        "  path=os.getcwd()+f\"/*.{i}\"\n",
        "  for j in glob.glob(path):\n",
        "    video_files.append(j)\n",
        "the_video=video_files[0].split(\"/\")[-1]    \n",
        "if the_video.endswith(\".mp4\"):\n",
        "      extension=\".mp4\"\n",
        "elif the_video.endswith(\".mp4\"):\n",
        "      extension=\".mp4\" \n",
        "elif the_video.endswith(\".mkv\"):\n",
        "      extension=\".mkv\"\n",
        "elif the_video.endswith(\".webm\"):\n",
        "      extension=\".webm\" \n",
        "elif the_video.endswith(\".mp4a\"):\n",
        "      extension=\".mp4a\"\n",
        "elif the_video.endswith(\".avi\"):\n",
        "      extension=\".avi\" \n",
        "elif the_video.endswith(\".mov\"):\n",
        "      extension=\".mov\"   \n",
        "os.rename(the_video,f\"input_video{extension}\")\n",
        "f_name=\"input_video\"  \n",
        "\n",
        "props = get_video_properties(f\"input_video{extension}\")\n",
        "print(f\"Resolution: {props['width']}×{props['height']}\")\n",
        "\n",
        "#@title Format- H:M:S, example- 00:10:30\n",
        "select_duration =\"full video\"#@param[\"full video\",\"some part\"]\n",
        "enter_start_time= \"00:00:00\" #@param {type:\"string\"}\n",
        "enter_end_time= \"00:00:60\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "start_time_float = enter_start_time.split(\":\")\n",
        "end_time_float = enter_end_time.split(\":\")\n",
        "start_time_in_second = (float(start_time_float[0])*60*60) + (float(start_time_float[1])*60) + float(start_time_float[2])\n",
        "end_time_in_second = (float(end_time_float[0])*60*60) + (float(end_time_float[1])*60) + float(end_time_float[2])\n",
        "cut_time_duration = end_time_in_second - start_time_in_second\n",
        "cut_time = str(datetime.timedelta(seconds=cut_time_duration))\n",
        "\n",
        "if  select_duration ==\"full video\":\n",
        "  video_duration=calculate_video_duration(f_name+f\"{extension}\")\n",
        "elif select_duration ==\"some part\":\n",
        "    cut_command=f\"ffmpeg -ss {enter_start_time} -i input_video{extension} -t {cut_time} -c copy cut{extension}\"\n",
        "    # cut_command=f\"ffmpeg -i input_video{extension} -vcodec copy -acodec copy -ss {enter_start_time} -t {cut_time} cut{extension}\"\n",
        "    os.system(cut_command)\n",
        "    os.remove(f\"input_video{extension}\")\n",
        "    os.rename(f\"cut{extension}\",f\"input_video{extension}\")\n",
        "    video_duration=calculate_video_duration(f_name+f\"{extension}\")\n",
        "input_video_duration = str(datetime.timedelta(seconds=video_duration))\n",
        "\n",
        "print(f\"input video duration {input_video_duration}\")\n",
        "html_code=\"<h3>Watch original youtube video</h3>\"\n",
        "display(HTML(html_code))\n",
        "youtube_video_display=\"\"\n",
        "youtube_video_display='<iframe width=\"'+str(560)+'\" height=\"'+str(315)+'\"\\nsrc=\"https://www.youtube.com/embed/'+youtube_id[-1]+'\"></iframe>'\n",
        "display(HTML(youtube_video_display))\n",
        "successful()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download successful\n",
            "Resolution: 1280×720\n",
            "input video duration 0:11:13.400000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Watch original youtube video</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<iframe width=\"560\" height=\"315\"\n",
              "src=\"https://www.youtube.com/embed/udeQhZHx-00\"></iframe>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uE1VBrqZVZzj"
      },
      "source": [
        "#Condition the video must have subtitle than download subtitle in your favorite  language.\n",
        "visit [downsub.com](https://downsub.com/) to download your youtube videos subtitle in your language and copy the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "ROEGgk1k33MQ",
        "outputId": "6f4cea43-1e6e-4440-bd6e-81581fb67d86"
      },
      "source": [
        "# @title ##**Paste the subtitle** { display-mode: \"form\" }\n",
        "\n",
        "paste_subtitles = \"It\\u2019s bread because I\\u2019ve been with you today.   Let's make a machine that makes rock, paper, scissors, scissors eyeballs using a media pipe.   The source code is on the Jackie Top, and I wrote it by 2 people and made it by referring to this code in Google Media Pipe Pose Station.   In order to explain the code written by 2 people more easily, I fork it like this to explain to you guys.   The code itself is very short because it consists of 77 lines. So, I will explain the simple principle of 105 machines that I am going to explain today.   First of all, if I explain the pipeline, it consists of 4 pipelines.   I learned a lot by looking at the code, especially in the gesture recognition part, that I can recognize it like this.   I learned it. First, the media pipe recognizes the achievements.   After implanting like this, the angle is calculated on the finger joint. There are many points of the sea of \\u200B\\u200Bthe finger with a lot of finger angle.   I named it Cooking Maker Int, but each of these points will have these angles   Nowadays and nowadays I calculated the angle. I keep it like this. I improve the angle of the vector vector.   It calculates the angle so that you can know how many times the finger is bent.   Thirdly, this angle was used to recognize gestures to protect it.   This is the rock, or the scissors are now learning. Finally, the winner is decided.   Mohyun's simple It's original, but since I used scissors, all the kids have a simple algorithm to determine the winner in this way   You can make a galvo machine through 4 steps. Let's start with the code that recognizes the limitations.   The package I used today will be used like this from the corridor media pipe Num Pa when it is opened.   When open, we will have some control over the webcam with v, so when we use the media pipe to recognize the line, we have at most several   Can you recognize the hand? So I\\u2019m going to do only one right now, so I\\u2019m going to type in \\u201Cwork\\u201D   After that, there are 11 gestures for gesture gestures, and 2 minutes is because they collected data on these various gestures.   Now, if I show you the iron in advance, what it is is like this. If you do this, e2   Hey, yeah because you are gay in Korea, but you usually do this in Europe or the United States in other countries. It doesn't work best.   Looks like the train now lacks a bit of training data. 3 then 4 5 5 Yes Spider-Man and Lock, and then this   626 Did you do it all like this?   Then he collected data that can recognize gestures. Feed these gestures with Yee Lee for 2 weeks.   Then, pull out 5 and give it a rock on the left. Next, let\\u2019s look at the weisser. So, if you pull out these 3 gestures, you join the outside.   I can make a machine, so I\\u2019m going to use only three of these 11 gestures   0 minutes 2 weeks feeding, 5 times the number, 9 times this is the vp, so this is each of these rocks   Then, it's the paper scissors. 0 5 9 Index Seo Young-ok, rock scissors, and match the paper.   So I made it separately like ips. It will recognize the hand with a media pipe. This is the u part, where you can control the volume with your finger on the dot.   I did it in making. If you don't know this part, please refer to the video of the finger volume control.   Then we will use 2 models this time. We will use the gesture recognition model.   So, there is a file called gesture train csv in the data collected by 2 people.   Gesture train csv files are collected in the data folder like this. So, all the achievements are stored here.   Next time, the label was saved at the end. I'm sorry Yong-young. Feed me that week. The mask under the fist sometimes gathers at this time, and various data is stored all the time.   Yes 4 There are about 110 training data right now, but it\\u2019s very little.   Well, if you want to improve the accuracy a lot, if you collect more of this data,   Angle it closer and collect the data like this by labeling it   I wear kd arrest in the open 10th place, and why k is called of the latest algorithm, so I use k DEARS dave knn to do the learning like this.   Well, one kl model has been well trained and will be in   In the use of video capture of 5 pc video, the wakeme image is long and then the webcam is 1 frame c of the image 1   All of these parts were the contents of the volume control, so I will skip it. Next, the part that calculates the angle of the most important part and recognizes the gesture   Remain so what if your hand a   So Eun-hee Son's watch So, if it's not the 5th period, if it's not the 5th period, I can recognize several improvements.   First, we use a gun to repeat it, and then we each have daily dots and red dots. The red dots are called joints, and this is xy jet.   I\\u2019m going to store the coordinates so there are 21 at the bottom of this side, because x is caught, xy is jet,   Save 3 and become 21 commas 3 So this landmark is saved for each joint, and the xy jet coordinates of the landmark are stored under 2 sets.   Then 21 comma 3 that array is created   Oh, here we calculate the angle with each joint intro vector. If you go to the Media Pepe document, there are indexes on various eat burners.   So, if you look at it, it seems that in the end, this index was added to v1 and dyron indexed to v2.   So, put it back in v So if you get on a boat except for Yeongha, then if you get on the movie Gohee,   Next, subtract this, subtract this 3, subtract 3, subtract the person, subtract the 1 and 2, subtract the person who works, except the person who is true.   Get all the vectors for each joint. Then, take out the fifth Kwon Eun-young and Orang.   Give me this, a sweet girl like this, like this, get a vector for each joint   So let's normalize it Normalize 2 We need to use the length of each vector Now we get the length Euclid 1   It's a formula to get the distance, but dividing it by the length, it will be normal rise.   The basic vector will come out and the job vector will be larger. After that, I'm not sure about this equation, but all arc cosines of the product   It is said that the angle is 9, and now I staren formation and arc cosine.   We get the angle and store it in a variable called Angry, so if you know about this equation, please let us know in the comments.   So I change the value of the angry radians to the values \\u200B\\u200Bof all kinds of this text. Did you make a gesture model with a student?   4 Take the trained knn model and do in-plus. So, change it to over tire ray and change it to a plotter 32-bit format, and then the data   After changing it to k, the realist K is like a spy and finds the price of life. So the result is the first ex of the resort.   So the index is stored here, and if the index is between and this rock beam   If there is one after signing up, it will display the valve result and if you are going to go to the valve result, if you don't see that spiderman or ok all those things   If you want to mark 11 seasons, you can use the code below to display all gestures.   You can use it. Because our purpose is to make Gal Weber, yoga is equivalent to this idiot.   I will show only gestures. Then I use pc off 15f text as this   Whether you wrote it in g's days, or whether it was a child of Cain's family, write the essence in writing.   Finally, draw a function that draws a brand mark on the knuckles using the Media Pipe Eight Roman Landmark function, and then   The requirement now is to actually show the picture. This will end a single dot pie.   Now I have made a model that can be recognized by Sun's Guyber. 4 knn is very fast and I am very satisfied with it 4   Like this, it is more recognized than rock, scissors, and it makes me glance at it like this   Yes, this watch works well on the side and on the side like this   Right this time, I'm going to look at the dual dot file, but it's a game where two guys play a ball ball.   So, for dual radio waves, you have to implant two hands first, so Max the Men's is 2   He said to recognize up to two hands, and here at the ips resort, he\\u2019s the result of this distribution, so he\\u2019ll store the coordinates in the hand. So   Here, we consider the essence of whether the result of Zester is buy of 2g in addition to RPASS realt.   Save it and save the position of each damage 2 on the finger here. So if you have more than 2 hands, there are only two anyway, but first   If it's been made like this and has 2 or more elements 4, the class runs this code and when the first person hits the rock, the first day when the file is two   If the second person played the ball, it was said that the second person also drew the ball, so it\\u2019s this because they saw the rock.   After that, the Japanese lost the scissors. So, there is a simple logic to determine whether or not the app is a cucumber.   Nougat now has a code like that to mark it in letters It's very simple I've been able to sign up and make a friend by doing this   When you run the dual dot file,   It\\u2019s very easy like this   Today, we learned how to make a rock, paper, scissors game using the Media Pipe Hand Landmark Detection Model.   Like this, I would have tried to make black ginseng using the image of a guy valve for noodles.   More than I think, we can make a model that recognizes 11 gestures with a simple algorithm such as kn using angles on the knuckles.   It\\u2019s very accurate. Then I\\u2019ll learn that you made a model. If you enjoyed it, please subscribe and like it. Next time, it\\u2019s more interesting and interesting.   I'll see you over the project. Bye\" #@param {type:\"string\"}\n",
        "do_you_want__original_video_background_music= \"No\"#@param [\"Yes\",\"No\"]\n",
        "if do_you_want__original_video_background_music== \"Yes\":\n",
        "  remove_list=[\"add_music_on_audio.mp3\",\"speed_match.mp3\",\"tts_audio.mp3\",\"vocals.wav\",\"accompaniment.wav\",f\"output{extension}\"]\n",
        "  for i in remove_list:\n",
        "    try:\n",
        "      os.remove(i)\n",
        "    except:\n",
        "      pass\n",
        "  #extract audio\n",
        "  os.system(f\"ffmpeg -i input_video{extension} input_audio.mp3\")\n",
        "  bash_f='spleeter separate -p spleeter:2stems -o output input_audio.mp3'\n",
        "  split_music_and_voice = os.system(bash_f)\n",
        "  if split_music_and_voice ==0:\n",
        "    voice=f'{parent_directory}/input_video/output/input_audio/vocals.wav'\n",
        "    shutil.move(voice,\".\")\n",
        "    music=f'{parent_directory}/input_video/output/input_audio/accompaniment.wav'\n",
        "    shutil.move(music,\".\")\n",
        "    os.system(\"rm -rf ./output\")\n",
        "    os.system(\"rm -rf ./pretrained_models\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "\n",
        "subtitles_language= \"English\" #@param [\"English\",\"korean\", \"Hindi\", \"Bengali\", \"Chinese\", \"Japanese\"]\n",
        "\n",
        "if subtitles_language == \"English\":\n",
        "    in_lang = \"en\"\n",
        "elif subtitles_language == \"korean\":\n",
        "    in_lang = \"ko\"    \n",
        "elif subtitles_language == \"Hindi\":\n",
        "    in_lang = \"hi\"\n",
        "elif subtitles_language == \"Bengali\":\n",
        "    in_lang = \"bn\"\n",
        "elif subtitles_language == \"Chinese\":\n",
        "    in_lang = \"zh-cn\"\n",
        "elif subtitles_language == \"Japanese\":\n",
        "    in_lang = \"ja\"\n",
        "\n",
        "\n",
        "english_accent =\"Default\" #@param [\"Default\",\"India\",\"United Kingdom\",\"United States\",\"Canada\",\"Australia\",\"Ireland\",\"South Africa\"]\n",
        "\n",
        "if english_accent == \"Default\":\n",
        "    tld = \"com\"\n",
        "elif english_accent == \"India\":\n",
        "    tld = \"co.in\"\n",
        "\n",
        "elif english_accent == \"United Kingdom\":\n",
        "    tld = \"co.uk\"\n",
        "elif english_accent == \"United States\":\n",
        "    tld = \"com\"\n",
        "elif english_accent == \"Canada\":\n",
        "    tld = \"ca\"\n",
        "elif english_accent == \"Australia\":\n",
        "    tld = \"com.au\"\n",
        "elif english_accent == \"Ireland\":\n",
        "    tld = \"ie\"\n",
        "elif english_accent == \"South Africa\":\n",
        "    tld = \"co.za\"\n",
        "\n",
        "\n",
        "\n",
        "tts = gTTS(paste_subtitles, lang=in_lang, tld=tld, slow=False)\n",
        "tts.save(f\"tts_audio.mp3\")\n",
        "audio = AudioSegment.from_file(\"tts_audio.mp3\")\n",
        "audio_duration=audio.duration_seconds\n",
        "a_float =audio_duration/video_duration\n",
        "formatted_float = \"{:.2f}\".format(a_float)\n",
        "sound = AudioSegment.from_file(\"tts_audio.mp3\")\n",
        "\n",
        "def speed_change(sound, speed=1.0):\n",
        "    # Manually override the frame_rate. This tells the computer how many\n",
        "    # samples to play per second\n",
        "    sound_with_altered_frame_rate = sound._spawn(sound.raw_data, overrides={\n",
        "         \"frame_rate\": int(sound.frame_rate * speed)\n",
        "      })\n",
        "     # convert the sound with altered frame rate to a standard frame rate\n",
        "     # so that regular playback programs will work right. They often only\n",
        "     # know how to play audio at standard frame rate (like 44.1k)\n",
        "    return sound_with_altered_frame_rate.set_frame_rate(sound.frame_rate)\n",
        "\n",
        "\n",
        "#synchronize_video_and_audio_time can change your pitch it sound may be bad\n",
        "synchronize_video_and_audio_time = \"Yes\"#@param [\"Yes\",\"No\"]  \n",
        "if synchronize_video_and_audio_time == \"Yes\":\n",
        "  match_video_speed_with_audio = speed_change(sound,float(formatted_float))\n",
        "  match_video_speed_with_audio.export('speed_match.mp3', format = 'mp3')\n",
        "\n",
        "\n",
        "overlay_audio=\"\"\n",
        "if do_you_want__original_video_background_music ==\"Yes\" and split_music_and_voice ==0:\n",
        "  if synchronize_video_and_audio_time == \"Yes\":\n",
        "    raw_audio=\"speed_match.mp3\"\n",
        "  elif synchronize_video_and_audio_time == \"No\":\n",
        "    raw_audio=\"input_audio.mp3\"\n",
        "  sound1 = AudioSegment.from_mp3(raw_audio)\n",
        "  sound2 = AudioSegment.from_mp3(\"accompaniment.wav\")\n",
        "  # mix sound2 with sound1, starting at 5000ms into sound1)\n",
        "  output = sound1.overlay(sound2, position=5000)\n",
        "  # save the result\n",
        "  output.export(\"add_music_on_audio.mp3\", format=\"mp3\")\n",
        "  overlay_audio=\"add_music_on_audio.mp3\"\n",
        "elif do_you_want__original_video_background_music ==\"No\":\n",
        "  overlay_audio=\"tts_audio.mp3\"\n",
        "  if synchronize_video_and_audio_time == \"Yes\":\n",
        "    overlay_audio = \"speed_match.mp3\"\n",
        "\n",
        "\n",
        "#add tts voice on video\n",
        "var=os.system(f\"ffmpeg -i input_video{extension} -i {overlay_audio} -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 output{extension}\")    \n",
        "\n",
        "\n",
        "export_file_name=subtitles_language+\"-\"+the_video.replace(youtube_id[-1],\"\")\n",
        "try:\n",
        "  os.remove(f\"{parent_directory}/output_video/{export_file_name}\")\n",
        "except:\n",
        "  pass\n",
        "try:\n",
        "  shutil.copy(f\"output{extension}\",f\"{parent_directory}/output_video/{export_file_name}\")\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "if var ==0:  \n",
        "  print(\"Your video location is: \")\n",
        "  print(f\"{parent_directory}/output_video/{export_file_name}\")\n",
        "  download_path=f\"{parent_directory}/output_video/{export_file_name}\"\n",
        "# ipd.Audio(\"/content/input_video/tts_audio.mp3\")\n",
        "#audio notification\n",
        "successful()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your video location is: \n",
            "/content/output_video/English-가위바위보 기계 만들기 - 손가락 인식 인공지능-.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4SkDrUVDR6Xl",
        "outputId": "b1a7355d-2174-4689-f307-59dd4db2dcc2"
      },
      "source": [
        "# @title ##**Download translate video** { display-mode: \"form\" }\n",
        "\n",
        "from google.colab import files\n",
        "files.download(download_path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ed1d33f7-d600-429f-891c-658424a734aa\", \"English-\\uac00\\uc704\\ubc14\\uc704\\ubcf4 \\uae30\\uacc4 \\ub9cc\\ub4e4\\uae30 - \\uc190\\uac00\\ub77d \\uc778\\uc2dd \\uc778\\uacf5\\uc9c0\\ub2a5-.mp4\", 46534828)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "5CQ7OIAIHy3J",
        "outputId": "fc8af19b-193a-4005-90f5-f3a1c6c99f65"
      },
      "source": [
        "# @title ##**Display translate video** { display-mode: \"form\" }\n",
        "\n",
        "from kora.drive import upload_public\n",
        "from IPython.display import HTML\n",
        "url = upload_public(download_path)\n",
        "clear_output()\n",
        "HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video src=https://drive.google.com/uc?id=1RayJlWeZHNXykRYZzUYK76XRs8TLSF6W width=500 controls/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}